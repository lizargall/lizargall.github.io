<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-aria_docs/faq" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">Project Aria FAQ | Liz Argall</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://lizargall.github.io/img/liz_social_card.jpg"><meta data-rh="true" name="twitter:image" content="https://lizargall.github.io/img/liz_social_card.jpg"><meta data-rh="true" property="og:url" content="https://lizargall.github.io/docs/aria_docs/faq"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="liz argall, elizabeth argall, technical writing, documentation, portfolio"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Project Aria FAQ | Liz Argall"><meta data-rh="true" name="description" content="Project Aria is a research program, with supporting spatial AI machine perception technologies and open science initiatives, created to serve as foundational building blocks for higher-level contextualized AI and the novel compute and interaction paradigms needed in order to make AR successful."><meta data-rh="true" property="og:description" content="Project Aria is a research program, with supporting spatial AI machine perception technologies and open science initiatives, created to serve as foundational building blocks for higher-level contextualized AI and the novel compute and interaction paradigms needed in order to make AR successful."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://lizargall.github.io/docs/aria_docs/faq"><link data-rh="true" rel="alternate" href="https://lizargall.github.io/docs/aria_docs/faq" hreflang="en"><link data-rh="true" rel="alternate" href="https://lizargall.github.io/docs/aria_docs/faq" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Liz Argall RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Liz Argall Atom Feed"><link rel="stylesheet" href="/assets/css/styles.3ecb062d.css">
<script src="/assets/js/runtime~main.bb70f43b.js" defer="defer"></script>
<script src="/assets/js/main.b225acf1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/pencil-solid.svg" alt="Liz Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/pencil-solid.svg" alt="Liz Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Liz Argall</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Portfolio</a></div><div class="navbar__items navbar__items--right"><a href="https://www.linkedin.com/in/lizargall/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Portfolio</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/aria-data-tools">Aria Data Tools</a><button aria-label="Expand sidebar category &#x27;Aria Data Tools&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/enmasse">En Masse Entertainment - Support Content, Wikis, Policies and Procedures</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/category/project-aria-docs">Project Aria Docs</a><button aria-label="Collapse sidebar category &#x27;Project Aria Docs&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/">Project Aria Docs Case Study</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/intro">Introduction to Project Aria Docs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/aria_docs/faq">Project Aria FAQ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/ARK_quickstart">Aria Glasses Quickstart</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/recording_profiles">Recording Profiles</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/timestamps_in_aria_vrs">Timestamp Definitions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/ticsync">Time Synchronization</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/category/mps---cloud-based-services">MPS - Cloud-Based Services</a><button aria-label="Expand sidebar category &#x27;MPS - Cloud-Based Services&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/sw_release_notes">ARK Release Notes</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/acrolinx">Acrolinx - Demos &amp; Training</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/warehouse_circus">Warehouse Circus - P&amp;P</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/pulp_stage">The Pulp Stage - Graphic Design &amp; Consulting</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/project-aria-docs"><span itemprop="name">Project Aria Docs</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Project Aria FAQ</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Project Aria Docs FAQ</h1>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Writing Sample</div><div class="admonitionContent_BuS1"><p>This page is an archive of technical writing I did for Project Aria. For the most up to date documentation go to <a href="https://facebookresearch.github.io/projectaria_tools/docs/intro" target="_blank" rel="noopener noreferrer">Project Aria Docs</a>. Some of the links will be broken, as I did not bring across the whole site.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-project-aria">What is Project Aria?<a class="hash-link" aria-label="Direct link to What is Project Aria?" title="Direct link to What is Project Aria?" href="/docs/aria_docs/faq#what-is-project-aria">​</a></h2>
<p><a href="https://www.projectaria.com/" target="_blank" rel="noopener noreferrer">Project Aria</a> is a research program, with supporting spatial AI machine perception technologies and open science initiatives, created to serve as foundational building blocks for higher-level contextualized AI and the novel compute and interaction paradigms needed in order to make AR successful.</p>
<p>Project Aria glasses are at the program&#x27;s core. A multimodal data collection device that collects data from the most human perspective. Project Aria glasses have five cameras (two Mono Scene, one RGB, and two Eye Tracking cameras) as well as non-visual sensors (two IMUs, magnetometer, barometer, GPS, Wi-Fi beacon, Bluetooth beacon and Microphones). On-device compute power is used to store information into VRS files, which preserves the integrity of individual sensor streams that are time aligned using shared time stamps.</p>
<p>The whitepaper, “<a href="https://arxiv.org/abs/2308.13561" target="_blank" rel="noopener noreferrer">Project Aria: A New Tool for Egocentric Multi-Modal AI Research</a>”, provides more details about Project Aria glasses, the data generated and motivation for the program.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-project-aria-data-is-available">What Project Aria data is available?<a class="hash-link" aria-label="Direct link to What Project Aria data is available?" title="Direct link to What Project Aria data is available?" href="/docs/aria_docs/faq#what-project-aria-data-is-available">​</a></h2>
<p>Researchers have used Project Aria to develop a wide range of powerful datasets. Open datasets powered by Project Aria data include:</p>
<ul>
<li><a href="https://www.projectaria.com/datasets/aea/" target="_blank" rel="noopener noreferrer">Aria Everyday Activities (AEA)</a> (Project Aria)</li>
<li><a href="https://www.projectaria.com/datasets/adt/" target="_blank" rel="noopener noreferrer">Aria Digital Twin (ADT)</a> (Project Aria)</li>
<li><a href="https://www.projectaria.com/datasets/ase/" target="_blank" rel="noopener noreferrer">Aria Synthetic Environments (ASE)</a> (Project Aria)</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/ego-exo4d" target="_blank" rel="noopener noreferrer">Ego-Exo4D</a> (Reality Labs FAIR collaboration with universities around the globe)</li>
<li><a href="https://ai.meta.com/datasets/mmcsg-dataset/" target="_blank" rel="noopener noreferrer">Multi-Modal Conversations in Smart Glasses</a> (MMCSG)</li>
<li><a href="https://www.projectaria.com/datasets/hot3d/" target="_blank" rel="noopener noreferrer">HOT3D</a> (Project Aria)</li>
<li><a href="https://www.projectaria.com/datasets/nymeria/" target="_blank" rel="noopener noreferrer">Nymeria</a> (Project Aria)</li>
</ul>
<p>Preview some Aria open data prior to downloading via the <a href="https://explorer.projectaria.com/" target="_blank" rel="noopener noreferrer">Aria Dataset Explorer</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-can-project-aria-be-used-for">What can Project Aria be used for?<a class="hash-link" aria-label="Direct link to What can Project Aria be used for?" title="Direct link to What can Project Aria be used for?" href="/docs/aria_docs/faq#what-can-project-aria-be-used-for">​</a></h2>
<p>Project Aria devices can be used to:</p>
<ul>
<li>Collect data<!-- -->
<ul>
<li>In addition to capturing data from a single device, TICSync can be used to capture time synchronized data from multiple Aria devices in a shared world location</li>
<li>Cloud based Machine Perception Services (MPS) are available to generate SLAM, Multi-Slam, Eye Gaze and Hand Tracking derived data outputs. Partner data is only used to serve MPS requests. Partner data is not available to Meta researchers or Meta’s affiliates.</li>
</ul>
</li>
<li>Stream data<!-- -->
<ul>
<li>Use the Project Aria Client SDK to stream and subscribe to data on your local machine</li>
</ul>
</li>
</ul>
<p>A range of models have been created using Aria data, including:</p>
<ul>
<li><a href="https://www.projectaria.com/tools/egoblur/" target="_blank" rel="noopener noreferrer">EgoBlur</a>: an open source AI model from Meta to preserve privacy by detecting and blurring PII from images. Designed to work with egocentric data (such as Aria data) and non-egocentric data.</li>
<li><a href="https://github.com/facebookresearch/projectaria_eyetracking" target="_blank" rel="noopener noreferrer">Project Aria Eye Tracking</a>: an open source inference code for the <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer">Pre March 2024 Eye Gaze Model</a> used by Machine Perception Services (MPS)</li>
<li><a href="https://www.projectaria.com/scenescript/" target="_blank" rel="noopener noreferrer">SceneScript</a>: an AI model and method to understand and describe 3D spaces</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-the-software-ecosystem">What is the software ecosystem?<a class="hash-link" aria-label="Direct link to What is the software ecosystem?" title="Direct link to What is the software ecosystem?" href="/docs/aria_docs/faq#what-is-the-software-ecosystem">​</a></h2>
<p>While some tools run on other platforms, when developing desktop tools we primarily support:</p>
<ul>
<li>x64 Linux distributions of:<!-- -->
<ul>
<li>Fedora 36, 37, 38</li>
<li>Ubuntu Jammy (22.04 LTS) and Focal (20.04 LTS)</li>
</ul>
</li>
<li>Mac Intel or Mac ARM-based (M1) with MacOS 11 (Big Sur) or newer</li>
</ul>
<p>To use the Python version of our tools, you&#x27;ll generally need Python 3.9+ (3.10+ if you are on <a href="https://support.apple.com/en-us/116943" target="_blank" rel="noopener noreferrer">Apple Silicon</a>). <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">Venv</a> virtual environments are used and tested for most applications, in most instances Conda should also work, with the exception of the Project Aria Client SDK.</p>
<ul>
<li><a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer">Python 3 download page</a></li>
<li>To check which version of Python 3 you have, use <code>python3 --version</code></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="project-aria-tools">Project Aria Tools<a class="hash-link" aria-label="Direct link to Project Aria Tools" title="Direct link to Project Aria Tools" href="/docs/aria_docs/faq#project-aria-tools">​</a></h3>
<p><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/data_utilities" target="_blank" rel="noopener noreferrer">Project Aria Tools</a> provides open source Python and C++ code and APIs for working with Aria data. Due to the multimodal nature of Project Aria data, the data is stored in <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs" target="_blank" rel="noopener noreferrer">VRS files</a>. Project Aria Tools provides API wrappers for using VRS tools, specifically tailored to working with Aria data. Using Project Aria Tools should make it easier to plug your data into other applications with more accessible formatting and labeling.</p>
<p>If there are VRS functions you wish Project Aria Tools had, please contact us using any of our <a href="https://facebookresearch.github.io/projectaria_tools/docs/support" target="_blank" rel="noopener noreferrer">Support Channels</a>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="apis">APIs<a class="hash-link" aria-label="Direct link to APIs" title="Direct link to APIs" href="/docs/aria_docs/faq#apis">​</a></h4>
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/data_provider" target="_blank" rel="noopener noreferrer">DataProvider</a>
<ul>
<li>Read Project Aria sequences and raw sensor data (VRS files)</li>
</ul>
</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/calibration" target="_blank" rel="noopener noreferrer">Calibration</a>
<ul>
<li>Retrieve calibration data and interact with Aria camera models</li>
</ul>
</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/mps" target="_blank" rel="noopener noreferrer">MPS</a>
<ul>
<li>Read Project Aria MPS (derived) data</li>
</ul>
</li>
<li>Images<!-- -->
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/visualization/visualization_python" target="_blank" rel="noopener noreferrer">Python Visualization Guide</a></li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/visualization/visualization_cpp" target="_blank" rel="noopener noreferrer">C++ Visualization Guide</a></li>
<li>Tooling enables users to:<!-- -->
<ul>
<li>Visualize time-synced recordings for one or more Project Aria sequences.</li>
<li>Visualize recordings and see 3D visualizations of pre-computed trajectory using time-synced data</li>
<li>Display an interactive visualization of the Aria VRS RGB frames along with MPS data (Closed loop trajectory, Global point cloud, Wearer eye gaze).</li>
<li>Display the relative position and orientation of Project Aria glasses sensors (cameras, IMUs, microphones, magnetometer &amp; barometer) in a common reference. (Python only)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Check the <a href="https://github.com/facebookresearch/projectaria_tools/tags" target="_blank" rel="noopener noreferrer">Project Aria Tools release log for the latest updates</a>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="data-review">Data Review<a class="hash-link" aria-label="Direct link to Data Review" title="Direct link to Data Review" href="/docs/aria_docs/faq#data-review">​</a></h4>
<p>The <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/advanced_code_snippets/vrs_to_mp4" target="_blank" rel="noopener noreferrer">vrs_to_mp4</a> script exports a VRS file to MP4 and was created to help researchers send files for review more easily. Please note, MP4 files will not contain the full sensor suite.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="code-samples">Code samples<a class="hash-link" aria-label="Direct link to Code samples" title="Direct link to Code samples" href="/docs/aria_docs/faq#code-samples">​</a></h4>
<ul>
<li><a href="https://github.com/facebookresearch/projectaria_tools/blob/main/tools/samples/vrs_mutation/Readme.md" target="_blank" rel="noopener noreferrer">VRS Mutation (C++)</a>
<ul>
<li>Create a copy of a VRS file that contains on the fly custom image modification (either from images in memory, or previously exported to disk):<!-- -->
<ul>
<li>Export VRS Frames</li>
<li>Modify the image frame<!-- -->
<ul>
<li>Such as blur/annotate objects manually or with a script</li>
</ul>
</li>
<li>Create copy of the VRS file that includes the modifications</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://github.com/facebookresearch/projectaria_tools/blob/main/tools/samples/python/automated_speech_recognition/Readme.md" target="_blank" rel="noopener noreferrer">Speech to Text (Python)</a>
<ul>
<li>Use <a href="https://github.com/SYSTRAN/faster-whisper" target="_blank" rel="noopener noreferrer">Faster Whisper</a> to run Whisper Speech Recognition on an Aria audio stream. The ASR outputs are time aligned with Aria Device Time.</li>
</ul>
</li>
<li><a href="https://github.com/facebookresearch/projectaria_tools/blob/main/tools/samples/python/SAM_eye_gaze_prompt/Readme.md" target="_blank" rel="noopener noreferrer">Run EfficientSAM with Eye Gaze image reprojection as prompt (Python)</a>
<ul>
<li>Use EfficientSAM to create image masks, based on eye gaze inference</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aria-research-kit-ark">Aria Research Kit (ARK)<a class="hash-link" aria-label="Direct link to Aria Research Kit (ARK)" title="Direct link to Aria Research Kit (ARK)" href="/docs/aria_docs/faq#aria-research-kit-ark">​</a></h4>
<p>Project Aria Tools code that is only relevant if you have access to Project Aria Glasses and are collecting your own data:</p>
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/request_mps/mps_cli" target="_blank" rel="noopener noreferrer">Project Aria MPS Command Line Interface (MPS CLI)</a> is a convenient way to request <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps" target="_blank" rel="noopener noreferrer">Machine Perception Services (MPS)</a>. Through the MPS CLI you can request:<!-- -->
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam" target="_blank" rel="noopener noreferrer">SLAM</a>, <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer">Eye Gaze</a> and <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/hand_tracking/" target="_blank" rel="noopener noreferrer">Hand Tracking</a> data.</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_multi_slam" target="_blank" rel="noopener noreferrer">Multi-sequence SLAM data</a> - SLAM data generated using multiple VRS recordings in a shared coordinate frame.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="aria-research-kit">Aria Research Kit<a class="hash-link" aria-label="Direct link to Aria Research Kit" title="Direct link to Aria Research Kit" href="/docs/aria_docs/faq#aria-research-kit">​</a></h3>
<p>The Aria Research Kit (ARK) provides Aria glasses, services and tools to enable researchers to gather and process their own Aria data. Go to <a href="https://www.projectaria.com/research-kit/" target="_blank" rel="noopener noreferrer">Aria Research Kit intro page</a> at <a href="https://www.projectaria.com/" target="_blank" rel="noopener noreferrer">projectaria.com</a> to find out more, or to apply to become a research partner.</p>
<p>The following SW and capabilities that are only relevant if you have access to Project Aria glasses and can collect your own data.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mobile-companion-app-required">Mobile Companion app (Required)<a class="hash-link" aria-label="Direct link to Mobile Companion app (Required)" title="Direct link to Mobile Companion app (Required)" href="/docs/aria_docs/faq#mobile-companion-app-required">​</a></h4>
<p>The Mobile Companion App, provides the ability to interact &amp; record with your Aria glasses via Bluetooth. When you receive your device, you must set them up using the Mobile Companion app, so that your glasses can receive OTA software updates.</p>
<p>If you&#x27;re using Android, your mobile device will need:</p>
<ul>
<li>Android OS version 10 or above installed</li>
<li>ARM64 processor preferred</li>
<li>(Optional) ARCore Depth API (<a href="https://developers.google.com/ar/devices" target="_blank" rel="noopener noreferrer">https://developers.google.com/ar/devices</a>) support needed for <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/eye_gaze_calibration" target="_blank" rel="noopener noreferrer">eye-tracking calibration</a></li>
<li>64-bit is preferred, although 32-bit is supported</li>
</ul>
<p>If you&#x27;re using iOS:</p>
<ul>
<li>OS version must be iOS 14 or above</li>
<li>(Optional) TrueDepth camera (iPhone X or later) needed for <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/eye_gaze_calibration" target="_blank" rel="noopener noreferrer">eye-tracking calibration</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="project-aria-client-sdk-with-cli">Project Aria Client SDK with CLI<a class="hash-link" aria-label="Direct link to Project Aria Client SDK with CLI" title="Direct link to Project Aria Client SDK with CLI" href="/docs/aria_docs/faq#project-aria-client-sdk-with-cli">​</a></h4>
<p>Through the Client SDK with CLI, you can directly interact with Aria glasses and stream data from the glasses to a computer. Not supported on Ubuntu Focal (20.04 LTS).</p>
<p>After connecting the Project Aria glasses and PC via USB or WiFi, the SDK enables users to:</p>
<ul>
<li>Retrieve device information, status and sensor calibration data</li>
<li>Configure, start and stop recording for a single device</li>
<li>Configure, start and stop recording for multiple time synchronized devices (using TICSync)</li>
<li>Configure, start and stop streaming from the glasses</li>
<li>Subscribe to streaming data from the glasses</li>
<li>Use TICSync to create time synchronized recordings with multiple Aria glasses</li>
</ul>
<p>You will need to install the Client SDK with CLI using a venv virtual environment. The authorization certificates required to pair your glasses with the computer will not be sent correctly in Conda.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mps-cli">MPS CLI<a class="hash-link" aria-label="Direct link to MPS CLI" title="Direct link to MPS CLI" href="/docs/aria_docs/faq#mps-cli">​</a></h4>
<p>Accessed via the PyPI installation of Project Aria Tools, the <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/request_mps/mps_cli" target="_blank" rel="noopener noreferrer">Project Aria MPS Command Line Interface (MPS CLI)</a> provides a streamlined way to request <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps" target="_blank" rel="noopener noreferrer">Machine Perception Services (MPS)</a>:</p>
<ul>
<li>Request <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam" target="_blank" rel="noopener noreferrer">SLAM</a>, <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer">Eye Gaze</a> and <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/hand_tracking" target="_blank" rel="noopener noreferrer">Hand Tracking</a> data</li>
<li>Request <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_multi_slam" target="_blank" rel="noopener noreferrer">Multi-Sequence SLAM data</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aria-studio">Aria Studio<a class="hash-link" aria-label="Direct link to Aria Studio" title="Direct link to Aria Studio" href="/docs/aria_docs/faq#aria-studio">​</a></h4>
<p>Aria Studio is an application will launch in your default web-browser and provides the ability to:</p>
<ul>
<li>Examine preview thumbnails and metadata of Aria recordings (on device or stored locally)</li>
<li>Transfer recordings from the device to the local computer or delete recordings stored on the device or local computer</li>
<li>Visualize recordings<!-- -->
<ul>
<li>We show visualizations of all the sensor streams except for audio. Audio outputs are not supported at this time.</li>
</ul>
</li>
<li>Group recordings for multi-sequence processing jobs<!-- -->
<ul>
<li>Grouped recordings are a special feature unlocked by Aria Studio. Users can group VRS recordings from anywhere in their directory for organizational purposes, or to request Multi-SLAM outputs.</li>
<li>Groups are stored on your local machine and associated with your Aria user account</li>
</ul>
</li>
<li>Request and manage Machine Perception Services (MPS) requests</li>
</ul>
<p>Like the MPS CLI, you can have granular control over settings such as uploads and download speeds by customizing <code>$HOME/.projectaria/mps.ini</code>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="desktop-companion-app">Desktop Companion app<a class="hash-link" aria-label="Direct link to Desktop Companion app" title="Direct link to Desktop Companion app" href="/docs/aria_docs/faq#desktop-companion-app">​</a></h4>
<p>The Desktop Companion app provides the ability to record, transfer, process, validate and visualize Aria data through a desktop interface. Users can also request MPS data for single recordings. Please note, Aria Studio is the preferred GUI for working with Aria data.</p>
<p>While Aria data can be downloaded using the Desktop app, it may be faster to <a href="/docs/aria_docs/ARK_quickstart#download-data">download the data using other means</a>.</p>
<p>The Desktop Companion app can be installed on:</p>
<ul>
<li>Mac Intel or Mac ARM-based (M1) with MacOS 11.3 (Big Sur) or newer</li>
<li>Windows 10 x86_64 with DirectX (or OpenGL but the latest drivers should be installed)</li>
<li>Windows 11 may work, but is not actively supported at this time</li>
<li>Linux, debian package for Ubuntu, 22.04 LTS version. The app was only tested for that specific version under Gnome 42.5 and X11 (X Server) as well as Wayland. Any other debian distribution (Ubuntu 22.04 fork such as Kubuntu, Mint etc.) or environment may or may not work.<!-- -->
<ul>
<li>V36 only, please use the <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/request_mps/mps_cli" target="_blank" rel="noopener noreferrer">MPS CLI</a> or <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/aria_studio" target="_blank" rel="noopener noreferrer">Aria Studio</a> to request Hand Tracking MPS</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="egoblur">EgoBlur<a class="hash-link" aria-label="Direct link to EgoBlur" title="Direct link to EgoBlur" href="/docs/aria_docs/faq#egoblur">​</a></h3>
<p>EgoBlur is an open source AI model from Meta to preserve privacy by detecting and blurring PII from images. We provide two FasterRCNN-based detector models, for face blurring and license plates and perform consistently across the full range of ‘responsible AI labels’, as defined by the <a href="https://ai.meta.com/datasets/casual-conversations-v2-dataset/" target="_blank" rel="noopener noreferrer">CCV2 dataset</a>.</p>
<ul>
<li>EgoBlur Research Paper - <a href="https://arxiv.org/abs/2308.13093" target="_blank" rel="noopener noreferrer">EgoBlur: Responsible Innovation in Aria</a></li>
<li><a href="https://www.projectaria.com/tools/egoblur/" target="_blank" rel="noopener noreferrer">About EgoBlur</a>
<ul>
<li><a href="https://www.projectaria.com/tools/egoblur/#accessEgoBlur" target="_blank" rel="noopener noreferrer">Download the Models</a></li>
</ul>
</li>
<li>EgoBlur VRS Utilities - C++ tool for working with Aria VRS files<!-- -->
<ul>
<li>Go to the <a href="https://github.com/facebookresearch/EgoBlur/blob/main/tools/README.md" target="_blank" rel="noopener noreferrer">EgoBlur VRS Utilities Readme</a> for detailed instructions</li>
</ul>
</li>
<li>EgoBlur Demo - Python3 tool for working with PNG, JPEG or MP4 files<!-- -->
<ul>
<li>Go to the <a href="https://github.com/facebookresearch/EgoBlur/blob/main/tools/README.md" target="_blank" rel="noopener noreferrer">EgoBlur Readme</a> for detailed instructions</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="project-aria-eye-tracking">Project Aria Eye Tracking<a class="hash-link" aria-label="Direct link to Project Aria Eye Tracking" title="Direct link to Project Aria Eye Tracking" href="/docs/aria_docs/faq#project-aria-eye-tracking">​</a></h3>
<p><a href="https://github.com/facebookresearch/projectaria_eyetracking" target="_blank" rel="noopener noreferrer">Project Aria Eye Tracking</a> provides an open source inference code for the <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer">Pre March 2024 Eye Gaze Model</a> used by MPS.</p>
<ul>
<li>Provides the ability to generate eye gaze data using the old model, if that is more suited to your research use case or if you’re not able to request MPS</li>
<li>This code can be used on downloaded data or when streaming data using the Aria Client SDK</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-i-use-aria-data">How do I use Aria data?<a class="hash-link" aria-label="Direct link to How do I use Aria data?" title="Direct link to How do I use Aria data?" href="/docs/aria_docs/faq#how-do-i-use-aria-data">​</a></h2>
<p>Because of Aria’s unique data structure, we recommend using Project Aria Tools as an interface to access the data via an abstraction (an X_provider string) that allows users to iterate through all the sensor recordings.</p>
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/aria_vrs" target="_blank" rel="noopener noreferrer">How Project Aria Uses VRS</a></li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/getting_started" target="_blank" rel="noopener noreferrer">Getting Started Guide</a> (view sample data via Jupyter Notebook or Google Colab)</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/installation/download_codebase" target="_blank" rel="noopener noreferrer">Download Project Aria Tools Codebase</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-i-use-the-imu-data">How do I use the IMU data?<a class="hash-link" aria-label="Direct link to How do I use the IMU data?" title="Direct link to How do I use the IMU data?" href="/docs/aria_docs/faq#how-do-i-use-the-imu-data">​</a></h3>
<div id="calibration"></div>
<p>We recommend using <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_trajectory" target="_blank" rel="noopener noreferrer">Trajectory MPS outputs</a> instead of raw IMU data wherever possible. Go to <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/mps" target="_blank" rel="noopener noreferrer">MPS Code Snippets</a> for how to load open loop or closed loop trajectory data.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-calibration-information-is-available">What calibration information is available?<a class="hash-link" aria-label="Direct link to What calibration information is available?" title="Direct link to What calibration information is available?" href="/docs/aria_docs/faq#what-calibration-information-is-available">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="general-calibration-concepts">General calibration concepts<a class="hash-link" aria-label="Direct link to General calibration concepts" title="Direct link to General calibration concepts" href="/docs/aria_docs/faq#general-calibration-concepts">​</a></h4>
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/coordinate_convention/2d_image_coordinate_system_convention" target="_blank" rel="noopener noreferrer">2D Image Coordinate System Conventions</a> (intrinsics)</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/coordinate_convention/3d_coordinate_frame_convention" target="_blank" rel="noopener noreferrer">3D Coordinate Frame Conventions</a> (extrinsics, non-visual sensor coordinate systems and CPF)</li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/calibration" target="_blank" rel="noopener noreferrer">Calibration Code Snippets</a></li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights" target="_blank" rel="noopener noreferrer">Tech Insights</a> - technical deeper dives on domain-specific topics, such as how we model sensors mathematically in calibration:<!-- -->
<ul>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights/camera_intrinsic_models" target="_blank" rel="noopener noreferrer">Camera intrinsic models</a></li>
<li><a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights/sensor_measurement_model" target="_blank" rel="noopener noreferrer">Sensor measurement model</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="slam-mps-calibration-data">SLAM MPS Calibration data<a class="hash-link" aria-label="Direct link to SLAM MPS Calibration data" title="Direct link to SLAM MPS Calibration data" href="/docs/aria_docs/faq#slam-mps-calibration-data">​</a></h4>
<p><code>Online_calibration.jsonl</code> is a SLAM MPS output that contains one json online calibration record per line. Each record is a json dict object that contains timestamp metadata and the result of online calibration for the cameras and IMUs.</p>
<p>The calibration parameters contain <a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights/camera_intrinsic_models" target="_blank" rel="noopener noreferrer">intrinsics</a> and <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/coordinate_convention/3d_coordinate_frame_convention" target="_blank" rel="noopener noreferrer">extrinsics</a> parameters for each sensor as well as a time offsets that best temporally align their data.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="in-session-eye-gaze-calibration">In-Session Eye Gaze Calibration<a class="hash-link" aria-label="Direct link to In-Session Eye Gaze Calibration" title="Direct link to In-Session Eye Gaze Calibration" href="/docs/aria_docs/faq#in-session-eye-gaze-calibration">​</a></h4>
<p>This is not related to standard calibration. <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/eye_gaze_calibration" target="_blank" rel="noopener noreferrer">In-Session Eye Gaze Calibration</a> enables researchers to improve the eye gaze estimations in Eye Gaze MPS outputs, enabling researchers to more accurately determine where wearers are looking during the recordings.</p>
<p>When users collect data using Aria glasses, they can initiate In-Session Eye Gaze Calibration. Once they’ve performed this task personalized, as well as general Eye Gaze MPS, can be generated. Every person is unique in terms of how they move their eyes and look at objects, so the personalized_eye_gaze estimation is expected to be more accurate for the individual.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="should-i-use-vrs-or-project-aria-tools">Should I use VRS or Project Aria Tools?<a class="hash-link" aria-label="Direct link to Should I use VRS or Project Aria Tools?" title="Direct link to Should I use VRS or Project Aria Tools?" href="/docs/aria_docs/faq#should-i-use-vrs-or-project-aria-tools">​</a></h3>
<p>Project Aria Tools provides VrsDataProvider which offers some, but not all, of the VRS API capabilities. Go to <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs" target="_blank" rel="noopener noreferrer">How Project Aria Uses VRS</a> for more information.</p>
<p>We’ve tailored VrsDataProvider to meet the requirements of people using Aria data. If there are capabilities in the VRS API that you would like to access when using Project Aria Tools, please use one of our <a href="https://facebookresearch.github.io/projectaria_tools/docs/support" target="_blank" rel="noopener noreferrer">Support channels</a> to let us know what you’re looking for and what features you would like.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-i-get-involved">How do I get involved?<a class="hash-link" aria-label="Direct link to How do I get involved?" title="Direct link to How do I get involved?" href="/docs/aria_docs/faq#how-do-i-get-involved">​</a></h2>
<p>The Project Aria <a href="https://www.projectaria.com/contact/" target="_blank" rel="noopener noreferrer">Contact Us</a> page contains a variety of ways to get in touch. We’d love to hear from you.</p>
<p>Download and explore our various <a href="https://www.projectaria.com/datasets/" target="_blank" rel="noopener noreferrer">open datasets</a> and let us know how it goes!</p>
<p>For questions or feature requests relating to Project Aria Tools, we encourage you to post to the <a href="https://github.com/facebookresearch/projectaria_tools/issues" target="_blank" rel="noopener noreferrer">Issues page on GitHub</a>.</p>
<p>Go to our <a href="https://facebookresearch.github.io/projectaria_tools/docs/attribution_citation" target="_blank" rel="noopener noreferrer">Attribution and Contributing page</a> if you’d like to find out how to cite Project Aria or contribute to our open tooling.</p>
<p><a href="https://www.projectaria.com/challenges/" target="_blank" rel="noopener noreferrer">Research Challenges</a> are posted to Projectaria.com. Open research challenges allow us to collectively accelerate the state-of-the-art with the community. We believe these challenges will help to establish a baseline for external researchers to build and foster reproducible research on egocentric Computer Vision and AI/ML algorithms for scene perception, reconstruction and understanding, and contextual AI.</p>
<p>If you’d like to collect your own data, or use Project Aria glasses in streaming applications go to <a href="https://www.projectaria.com/research-kit/" target="_blank" rel="noopener noreferrer">Aria Research Kit intro page</a> at <a href="https://www.projectaria.com/" target="_blank" rel="noopener noreferrer">projectaria.com</a> to find out how to become a research partner.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/aria_docs/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction to Project Aria Docs</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/aria_docs/ARK_quickstart"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Aria Glasses Quickstart</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#what-is-project-aria">What is Project Aria?</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#what-project-aria-data-is-available">What Project Aria data is available?</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#what-can-project-aria-be-used-for">What can Project Aria be used for?</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#what-is-the-software-ecosystem">What is the software ecosystem?</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#project-aria-tools">Project Aria Tools</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#aria-research-kit">Aria Research Kit</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#egoblur">EgoBlur</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#project-aria-eye-tracking">Project Aria Eye Tracking</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#how-do-i-use-aria-data">How do I use Aria data?</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#how-do-i-use-the-imu-data">How do I use the IMU data?</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#what-calibration-information-is-available">What calibration information is available?</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#should-i-use-vrs-or-project-aria-tools">Should I use VRS or Project Aria Tools?</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/aria_docs/faq#how-do-i-get-involved">How do I get involved?</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">External Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebookresearch/hot3d/commit/a23c9dc4aa1e0679a5089af376e7cbd32434c2f5" target="_blank" rel="noopener noreferrer" class="footer__link-item">HOT3D README Commit<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.graphicmedicine.org/comic-reviews/past-tense-facing-family-secrets-and-finding-myself-in-therapy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Book Review: Past Tense<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Featured Content</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/aria_docs/faq">Project Aria FAQ</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/aria_docs/mps/mps_cli_guide">MPS Guide - Cloud Services</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/acrolinx">Acrolinx - an AI Content Governance Tool</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/lizargall/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/lizargall" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>