<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-aria_docs/faq" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Project Aria FAQ | Liz Argall</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://lizargall.github.io/img/liz_social_card.jpg"><meta data-rh="true" name="twitter:image" content="https://lizargall.github.io/img/liz_social_card.jpg"><meta data-rh="true" property="og:url" content="https://lizargall.github.io/docs/aria_docs/faq"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="liz argall, elizabeth argall, technical writing, technical writer"><meta data-rh="true" name="author" content="Liz Argall"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Project Aria FAQ | Liz Argall"><meta data-rh="true" name="description" content="Project Aria is a research program, with supporting spatial AI machine perception technologies and open science initiatives, created to serve as foundational building blocks for higher-level contextualized AI and the novel compute and interaction paradigms needed in order to make AR successful."><meta data-rh="true" property="og:description" content="Project Aria is a research program, with supporting spatial AI machine perception technologies and open science initiatives, created to serve as foundational building blocks for higher-level contextualized AI and the novel compute and interaction paradigms needed in order to make AR successful."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://lizargall.github.io/docs/aria_docs/faq"><link data-rh="true" rel="alternate" href="https://lizargall.github.io/docs/aria_docs/faq" hreflang="en"><link data-rh="true" rel="alternate" href="https://lizargall.github.io/docs/aria_docs/faq" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://WM5BCONW0N-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Project Aria Docs - open source","item":"https://lizargall.github.io/docs/category/project-aria-docs---open-source"},{"@type":"ListItem","position":2,"name":"Project Aria FAQ","item":"https://lizargall.github.io/docs/aria_docs/faq"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Liz Argall RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Liz Argall Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Liz Argall" href="/opensearch.xml">
<meta name="google-site-verification" content="k1qcZWgLmNpiwsIkdJiK_Ra66dDxon77PSqpaDj7_fE"><link rel="stylesheet" href="/assets/css/styles.dfef631a.css">
<script src="/assets/js/runtime~main.66d2bece.js" defer="defer"></script>
<script src="/assets/js/main.d2764488.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/pencil-solid.svg" alt="Liz Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/pencil-solid.svg" alt="Liz Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Liz Argall</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Portfolio</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/work">Work With Me</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://mailchi.mp/520551e04a4d/documentarians-rock" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Subscribe<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://github.com/lizargall" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://www.linkedin.com/in/lizargall/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts="Meta+k"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 24 24" aria-hidden="true"><circle cx="11" cy="11" r="8" stroke="currentColor" fill="none" stroke-width="1.4"></circle><path d="m21 21-4.3-4.3" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="Portfolio" class="linkLabel_WmDU">Portfolio</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/tea"><span title="How to Make a Cup of Tea" class="linkLabel_WmDU">How to Make a Cup of Tea</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/category/aria-data-tools---open-source"><span title="Aria Data Tools - open source" class="categoryLinkLabel_W154">Aria Data Tools - open source</span></a><button aria-label="Expand sidebar category &#x27;Aria Data Tools - open source&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/enmasse"><span title="En Masse Entertainment - Support Content, Wikis, Policies and Procedures" class="linkLabel_WmDU">En Masse Entertainment - Support Content, Wikis, Policies and Procedures</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/docs/category/project-aria-docs---open-source"><span title="Project Aria Docs - open source" class="categoryLinkLabel_W154">Project Aria Docs - open source</span></a><button aria-label="Collapse sidebar category &#x27;Project Aria Docs - open source&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/"><span title="Project Aria Docs Case Study" class="linkLabel_WmDU">Project Aria Docs Case Study</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/intro"><span title="Introduction to Project Aria Docs" class="linkLabel_WmDU">Introduction to Project Aria Docs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/aria_docs/faq"><span title="Project Aria FAQ" class="linkLabel_WmDU">Project Aria FAQ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/ARK_quickstart"><span title="Getting Started With Aria Glasses" class="linkLabel_WmDU">Getting Started With Aria Glasses</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/ticsync"><span title="How to Create Time-Synchronized Recordings With Multiple Aria Devices" class="linkLabel_WmDU">How to Create Time-Synchronized Recordings With Multiple Aria Devices</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/recording_profiles"><span title="Recording Profiles" class="linkLabel_WmDU">Recording Profiles</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/timestamps_in_aria_vrs"><span title="Timestamp Definitions" class="linkLabel_WmDU">Timestamp Definitions</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/docs/category/mps---cloud-based-services"><span title="MPS - Cloud-Based Services" class="categoryLinkLabel_W154">MPS - Cloud-Based Services</span></a><button aria-label="Expand sidebar category &#x27;MPS - Cloud-Based Services&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/aria_docs/sw_release_notes"><span title="ARK Release Notes" class="linkLabel_WmDU">ARK Release Notes</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/acrolinx"><span title="Acrolinx - Demos &amp; Training" class="linkLabel_WmDU">Acrolinx - Demos &amp; Training</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/warehouse_circus"><span title="Warehouse Circus - P&amp;P" class="linkLabel_WmDU">Warehouse Circus - P&amp;P</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/pulp_stage"><span title="The Pulp Stage - Graphic Design &amp; Consulting" class="linkLabel_WmDU">The Pulp Stage - Graphic Design &amp; Consulting</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/category/project-aria-docs---open-source"><span>Project Aria Docs - open source</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Project Aria FAQ</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Project Aria Docs FAQ</h1></header>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Writing Sample</div><div class="admonitionContent_BuS1"><p>This page is based on technical writing I did for Project Aria. For the most up to date documentation go to <a href="https://facebookresearch.github.io/projectaria_tools/docs/intro" target="_blank" rel="noopener noreferrer" class="">Project Aria Docs</a>.</p></div></div>
<p>This Project Aria FAQ covers:</p>
<ul>
<li class=""><a href="#what-is-project-aria" class="">What is Project Aria</a></li>
<li class=""><a href="#what-project-aria-data-is-available" class="">What Project Aria data is available?</a></li>
<li class=""><a href="#what-can-project-aria-be-used-for" class="">What can Project Aria be used for?</a></li>
<li class=""><a href="#what-is-the-software-ecosystem" class="">What is the software ecosystem?</a>
<ul>
<li class=""><a href="#project-aria-tools" class="">Project Aria Tools</a>
<ul>
<li class=""><a href="#apis" class="">APIs</a></li>
<li class=""><a href="#data-review" class="">Data review</a></li>
<li class=""><a href="#code-samples" class="">Code samples</a></li>
<li class=""><a href="#aria-research-kit-ark" class="">Aria Research Kit (ARK)</a>
<ul>
<li class="">ARK tools contained within this open source tools kit</li>
</ul>
</li>
</ul>
</li>
<li class=""><a href="#aria-research-kit" class="">Aria Research Kit</a>
<ul>
<li class=""><a href="#mobile-companion-app-required" class="">Mobile Companion app</a></li>
<li class=""><a href="#project-aria-client-sdk-with-cli" class="">Project Aria Client SDK with CLI</a></li>
<li class=""><a href="#mps-cli" class="">MPS CLI</a></li>
<li class=""><a href="#aria-studio" class="">Aria Studio</a></li>
<li class=""><a href="#desktop-companion-app" class="">Desktop Companion app</a></li>
</ul>
</li>
<li class=""><a href="#egoblur" class="">EgoBlur</a></li>
<li class=""><a href="#project-aria-eye-tracking" class="">Project Aria Eye Tracking</a></li>
</ul>
</li>
<li class=""><a href="#how-do-i-use-aria-data" class="">How do I use Aria data?</a>
<ul>
<li class=""><a href="#how-do-i-use-the-imu-data" class="">How do I use the IMU data?</a></li>
<li class=""><a href="#what-calibration-information-is-available" class="">What calibration information is available?</a></li>
<li class=""><a href="#should-i-use-vrs-or-project-aria-tools" class="">Should I use VRS or Project Aria Tools?</a></li>
</ul>
</li>
<li class=""><a href="#how-do-i-get-involved" class="">How do I get involved?</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-project-aria">What is Project Aria?<a href="#what-is-project-aria" class="hash-link" aria-label="Direct link to What is Project Aria?" title="Direct link to What is Project Aria?" translate="no">​</a></h2>
<p><a href="https://www.projectaria.com/" target="_blank" rel="noopener noreferrer" class="">Project Aria</a> is a research program, with supporting spatial AI machine perception technologies and open science initiatives, created to serve as foundational building blocks for higher-level contextualized AI and the novel compute and interaction paradigms needed in order to make AR successful.</p>
<p>Project Aria glasses are at the program&#x27;s core. A multimodal data collection device that collects data from the most human perspective. Project Aria glasses have five cameras (two Mono Scene, one RGB, and two Eye Tracking cameras) as well as non-visual sensors (two IMUs, magnetometer, barometer, GPS, Wi-Fi beacon, Bluetooth beacon and Microphones). On-device compute power is used to store information into VRS files, which preserves the integrity of individual sensor streams that are time aligned using shared time stamps.</p>
<p>The whitepaper, “<a href="https://arxiv.org/abs/2308.13561" target="_blank" rel="noopener noreferrer" class="">Project Aria: A New Tool for Egocentric Multi-Modal AI Research</a>”, provides more details about Project Aria glasses, the data generated and motivation for the program.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-project-aria-data-is-available">What Project Aria data is available?<a href="#what-project-aria-data-is-available" class="hash-link" aria-label="Direct link to What Project Aria data is available?" title="Direct link to What Project Aria data is available?" translate="no">​</a></h2>
<p>Researchers have used Project Aria to develop a wide range of powerful datasets. Open datasets powered by Project Aria data include:</p>
<ul>
<li class=""><a href="https://www.projectaria.com/datasets/aea/" target="_blank" rel="noopener noreferrer" class="">Aria Everyday Activities (AEA)</a> (Project Aria)</li>
<li class=""><a href="https://www.projectaria.com/datasets/adt/" target="_blank" rel="noopener noreferrer" class="">Aria Digital Twin (ADT)</a> (Project Aria)</li>
<li class=""><a href="https://www.projectaria.com/datasets/ase/" target="_blank" rel="noopener noreferrer" class="">Aria Synthetic Environments (ASE)</a> (Project Aria)</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/ego-exo4d" target="_blank" rel="noopener noreferrer" class="">Ego-Exo4D</a> (Reality Labs FAIR collaboration with universities around the globe)</li>
<li class=""><a href="https://ai.meta.com/datasets/mmcsg-dataset/" target="_blank" rel="noopener noreferrer" class="">Multi-Modal Conversations in Smart Glasses</a> (MMCSG)</li>
<li class=""><a href="https://www.projectaria.com/datasets/hot3d/" target="_blank" rel="noopener noreferrer" class="">HOT3D</a> (Project Aria)</li>
<li class=""><a href="https://www.projectaria.com/datasets/nymeria/" target="_blank" rel="noopener noreferrer" class="">Nymeria</a> (Project Aria)</li>
</ul>
<p>Preview some Aria open data prior to downloading via the <a href="https://explorer.projectaria.com/" target="_blank" rel="noopener noreferrer" class="">Aria Dataset Explorer</a>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-can-project-aria-be-used-for">What can Project Aria be used for?<a href="#what-can-project-aria-be-used-for" class="hash-link" aria-label="Direct link to What can Project Aria be used for?" title="Direct link to What can Project Aria be used for?" translate="no">​</a></h2>
<p>Project Aria devices can be used to:</p>
<ul>
<li class="">Collect data<!-- -->
<ul>
<li class="">In addition to capturing data from a single device, TICSync can be used to capture time-synchronized data from multiple Aria devices in a shared world location</li>
<li class="">Cloud based Machine Perception Services (MPS) are available to generate SLAM, Multi-Slam, Eye Gaze and Hand Tracking derived data outputs. Partner data is only used to serve MPS requests. Partner data is not available to Meta researchers or Meta’s affiliates.</li>
</ul>
</li>
<li class="">Stream data<!-- -->
<ul>
<li class="">Use the Project Aria Client SDK to stream and subscribe to data on your local machine</li>
</ul>
</li>
</ul>
<p>A range of models have been created using Aria data, including:</p>
<ul>
<li class=""><a href="https://www.projectaria.com/tools/egoblur/" target="_blank" rel="noopener noreferrer" class="">EgoBlur</a>: an open source AI model from Meta to preserve privacy by detecting and blurring PII from images. Designed to work with egocentric data (such as Aria data) and non-egocentric data.</li>
<li class=""><a href="https://github.com/facebookresearch/projectaria_eyetracking" target="_blank" rel="noopener noreferrer" class="">Project Aria Eye Tracking</a>: an open source inference code for the <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer" class="">Pre March 2024 Eye Gaze Model</a> used by Machine Perception Services (MPS)</li>
<li class=""><a href="https://www.projectaria.com/scenescript/" target="_blank" rel="noopener noreferrer" class="">SceneScript</a>: an AI model and method to understand and describe 3D spaces</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-the-software-ecosystem">What is the software ecosystem?<a href="#what-is-the-software-ecosystem" class="hash-link" aria-label="Direct link to What is the software ecosystem?" title="Direct link to What is the software ecosystem?" translate="no">​</a></h2>
<p>While some tools run on other platforms, when developing desktop tools we primarily support:</p>
<ul>
<li class="">x64 Linux distributions of:<!-- -->
<ul>
<li class="">Fedora 36, 37, 38</li>
<li class="">Ubuntu Jammy (22.04 LTS) and Focal (20.04 LTS)</li>
</ul>
</li>
<li class="">Mac Intel or Mac ARM-based (M1) with MacOS 11 (Big Sur) or newer</li>
</ul>
<p>To use the Python version of our tools, you&#x27;ll generally need Python 3.9+ (3.10+ if you are on <a href="https://support.apple.com/en-us/116943" target="_blank" rel="noopener noreferrer" class="">Apple Silicon</a>). <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer" class="">Venv</a> virtual environments are used and tested for most applications, in most instances Conda should also work, with the exception of the Project Aria Client SDK.</p>
<ul>
<li class=""><a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer" class="">Python 3 download page</a></li>
<li class="">To check which version of Python 3 you have, use <code>python3 --version</code></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="project-aria-tools">Project Aria Tools<a href="#project-aria-tools" class="hash-link" aria-label="Direct link to Project Aria Tools" title="Direct link to Project Aria Tools" translate="no">​</a></h3>
<p><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/data_utilities" target="_blank" rel="noopener noreferrer" class="">Project Aria Tools</a> provides open source Python and C++ code and APIs for working with Aria data. Due to the multimodal nature of Project Aria data, the data is stored in <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs" target="_blank" rel="noopener noreferrer" class="">VRS files</a>. Project Aria Tools provides API wrappers for using VRS tools, specifically tailored to working with Aria data. Using Project Aria Tools should make it easier to plug your data into other applications with more accessible formatting and labeling.</p>
<p>If there are VRS functions you wish Project Aria Tools had, please contact us using any of our <a href="https://facebookresearch.github.io/projectaria_tools/docs/support" target="_blank" rel="noopener noreferrer" class="">Support Channels</a>.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="apis">APIs<a href="#apis" class="hash-link" aria-label="Direct link to APIs" title="Direct link to APIs" translate="no">​</a></h4>
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/data_provider" target="_blank" rel="noopener noreferrer" class="">DataProvider</a>
<ul>
<li class="">Read Project Aria sequences and raw sensor data (VRS files)</li>
</ul>
</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/calibration" target="_blank" rel="noopener noreferrer" class="">Calibration</a>
<ul>
<li class="">Retrieve calibration data and interact with Aria camera models</li>
</ul>
</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/mps" target="_blank" rel="noopener noreferrer" class="">MPS</a>
<ul>
<li class="">Read Project Aria MPS (derived) data</li>
</ul>
</li>
<li class="">Images<!-- -->
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/visualization/visualization_python" target="_blank" rel="noopener noreferrer" class="">Python Visualization Guide</a></li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/visualization/visualization_cpp" target="_blank" rel="noopener noreferrer" class="">C++ Visualization Guide</a></li>
<li class="">Tooling enables users to:<!-- -->
<ul>
<li class="">Visualize time-synced recordings for one or more Project Aria sequences.</li>
<li class="">Visualize recordings and see 3D visualizations of pre-computed trajectory using time-synced data</li>
<li class="">Display an interactive visualization of the Aria VRS RGB frames along with MPS data (Closed loop trajectory, Global point cloud, Wearer eye gaze).</li>
<li class="">Display the relative position and orientation of Project Aria glasses sensors (cameras, IMUs, microphones, magnetometer &amp; barometer) in a common reference. (Python only)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Check the <a href="https://github.com/facebookresearch/projectaria_tools/tags" target="_blank" rel="noopener noreferrer" class="">Project Aria Tools release log for the latest updates</a>.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-review">Data Review<a href="#data-review" class="hash-link" aria-label="Direct link to Data Review" title="Direct link to Data Review" translate="no">​</a></h4>
<p>The <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/advanced_code_snippets/vrs_to_mp4" target="_blank" rel="noopener noreferrer" class="">vrs_to_mp4</a> script exports a VRS file to MP4 and was created to help researchers send files for review more easily. Please note, MP4 files will not contain the full sensor suite.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-samples">Code samples<a href="#code-samples" class="hash-link" aria-label="Direct link to Code samples" title="Direct link to Code samples" translate="no">​</a></h4>
<ul>
<li class=""><a href="https://github.com/facebookresearch/projectaria_tools/blob/main/tools/samples/vrs_mutation/Readme.md" target="_blank" rel="noopener noreferrer" class="">VRS Mutation (C++)</a>
<ul>
<li class="">Create a copy of a VRS file that contains on the fly custom image modification (either from images in memory, or previously exported to disk):<!-- -->
<ul>
<li class="">Export VRS Frames</li>
<li class="">Modify the image frame<!-- -->
<ul>
<li class="">Such as blur/annotate objects manually or with a script</li>
</ul>
</li>
<li class="">Create copy of the VRS file that includes the modifications</li>
</ul>
</li>
</ul>
</li>
<li class=""><a href="https://github.com/facebookresearch/projectaria_tools/blob/main/tools/samples/python/automated_speech_recognition/Readme.md" target="_blank" rel="noopener noreferrer" class="">Speech to Text (Python)</a>
<ul>
<li class="">Use <a href="https://github.com/SYSTRAN/faster-whisper" target="_blank" rel="noopener noreferrer" class="">Faster Whisper</a> to run Whisper Speech Recognition on an Aria audio stream. The ASR outputs are time aligned with Aria Device Time.</li>
</ul>
</li>
<li class=""><a href="https://github.com/facebookresearch/projectaria_tools/blob/main/tools/samples/python/SAM_eye_gaze_prompt/Readme.md" target="_blank" rel="noopener noreferrer" class="">Run EfficientSAM with Eye Gaze image reprojection as prompt (Python)</a>
<ul>
<li class="">Use EfficientSAM to create image masks, based on eye gaze inference</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="aria-research-kit-ark">Aria Research Kit (ARK)<a href="#aria-research-kit-ark" class="hash-link" aria-label="Direct link to Aria Research Kit (ARK)" title="Direct link to Aria Research Kit (ARK)" translate="no">​</a></h4>
<p>Project Aria Tools code that is only relevant if you have access to Project Aria Glasses and are collecting your own data:</p>
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/request_mps/mps_cli" target="_blank" rel="noopener noreferrer" class="">Project Aria MPS Command Line Interface (MPS CLI)</a> is a convenient way to request <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps" target="_blank" rel="noopener noreferrer" class="">Machine Perception Services (MPS)</a>. Through the MPS CLI you can request:<!-- -->
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam" target="_blank" rel="noopener noreferrer" class="">SLAM</a>, <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer" class="">Eye Gaze</a> and <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/hand_tracking/" target="_blank" rel="noopener noreferrer" class="">Hand Tracking</a> data.</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_multi_slam" target="_blank" rel="noopener noreferrer" class="">Multi-sequence SLAM data</a> - SLAM data generated using multiple VRS recordings in a shared coordinate frame.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="aria-research-kit">Aria Research Kit<a href="#aria-research-kit" class="hash-link" aria-label="Direct link to Aria Research Kit" title="Direct link to Aria Research Kit" translate="no">​</a></h3>
<p>The Aria Research Kit (ARK) provides Aria glasses, services and tools to enable researchers to gather and process their own Aria data. Go to <a href="https://www.projectaria.com/research-kit/" target="_blank" rel="noopener noreferrer" class="">Aria Research Kit intro page</a> at <a href="https://www.projectaria.com/" target="_blank" rel="noopener noreferrer" class="">projectaria.com</a> to find out more, or to apply to become a research partner.</p>
<p>The following SW and capabilities that are only relevant if you have access to Project Aria glasses and can collect your own data.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="mobile-companion-app-required">Mobile Companion app (Required)<a href="#mobile-companion-app-required" class="hash-link" aria-label="Direct link to Mobile Companion app (Required)" title="Direct link to Mobile Companion app (Required)" translate="no">​</a></h4>
<p>The Mobile Companion App, provides the ability to interact &amp; record with your Aria glasses via Bluetooth. When you receive your device, you must set them up using the Mobile Companion app, so that your glasses can receive OTA software updates.</p>
<p>If you&#x27;re using Android, your mobile device will need:</p>
<ul>
<li class="">Android OS version 10 or above installed</li>
<li class="">ARM64 processor preferred</li>
<li class="">(Optional) ARCore Depth API (<a href="https://developers.google.com/ar/devices" target="_blank" rel="noopener noreferrer" class="">https://developers.google.com/ar/devices</a>) support needed for <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/eye_gaze_calibration" target="_blank" rel="noopener noreferrer" class="">eye-tracking calibration</a></li>
<li class="">64-bit is preferred, although 32-bit is supported</li>
</ul>
<p>If you&#x27;re using iOS:</p>
<ul>
<li class="">OS version must be iOS 14 or above</li>
<li class="">(Optional) TrueDepth camera (iPhone X or later) needed for <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/eye_gaze_calibration" target="_blank" rel="noopener noreferrer" class="">eye-tracking calibration</a></li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="project-aria-client-sdk-with-cli">Project Aria Client SDK with CLI<a href="#project-aria-client-sdk-with-cli" class="hash-link" aria-label="Direct link to Project Aria Client SDK with CLI" title="Direct link to Project Aria Client SDK with CLI" translate="no">​</a></h4>
<p>Through the Client SDK with CLI, you can directly interact with Aria glasses and stream data from the glasses to a computer. Not supported on Ubuntu Focal (20.04 LTS).</p>
<p>After connecting the Project Aria glasses and PC via USB or WiFi, the SDK enables users to:</p>
<ul>
<li class="">Retrieve device information, status and sensor calibration data</li>
<li class="">Configure, start and stop recording for a single device</li>
<li class="">Configure, start and stop recording for multiple time-synchronized devices (using TICSync)</li>
<li class="">Configure, start and stop streaming from the glasses</li>
<li class="">Subscribe to streaming data from the glasses</li>
<li class="">Use TICSync to create time-synchronized recordings with multiple Aria glasses</li>
</ul>
<p>You will need to install the Client SDK with CLI using a venv virtual environment. The authorization certificates required to pair your glasses with the computer will not be sent correctly in Conda.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="mps-cli">MPS CLI<a href="#mps-cli" class="hash-link" aria-label="Direct link to MPS CLI" title="Direct link to MPS CLI" translate="no">​</a></h4>
<p>Accessed via the PyPI installation of Project Aria Tools, the <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/request_mps/mps_cli" target="_blank" rel="noopener noreferrer" class="">Project Aria MPS Command Line Interface (MPS CLI)</a> provides a streamlined way to request <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps" target="_blank" rel="noopener noreferrer" class="">Machine Perception Services (MPS)</a>:</p>
<ul>
<li class="">Request <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam" target="_blank" rel="noopener noreferrer" class="">SLAM</a>, <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer" class="">Eye Gaze</a> and <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/hand_tracking" target="_blank" rel="noopener noreferrer" class="">Hand Tracking</a> data</li>
<li class="">Request <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_multi_slam" target="_blank" rel="noopener noreferrer" class="">Multi-Sequence SLAM data</a></li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="aria-studio">Aria Studio<a href="#aria-studio" class="hash-link" aria-label="Direct link to Aria Studio" title="Direct link to Aria Studio" translate="no">​</a></h4>
<p>Aria Studio is an application will launch in your default web-browser and provides the ability to:</p>
<ul>
<li class="">Examine preview thumbnails and metadata of Aria recordings (on device or stored locally)</li>
<li class="">Transfer recordings from the device to the local computer or delete recordings stored on the device or local computer</li>
<li class="">Visualize recordings<!-- -->
<ul>
<li class="">We show visualizations of all the sensor streams except for audio. Audio outputs are not supported at this time.</li>
</ul>
</li>
<li class="">Group recordings for multi-sequence processing jobs<!-- -->
<ul>
<li class="">Grouped recordings are a special feature unlocked by Aria Studio. Users can group VRS recordings from anywhere in their directory for organizational purposes, or to request Multi-SLAM outputs.</li>
<li class="">Groups are stored on your local machine and associated with your Aria user account</li>
</ul>
</li>
<li class="">Request and manage Machine Perception Services (MPS) requests</li>
</ul>
<p>Like the MPS CLI, you can have granular control over settings such as uploads and download speeds by customizing <code>$HOME/.projectaria/mps.ini</code>.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="desktop-companion-app">Desktop Companion app<a href="#desktop-companion-app" class="hash-link" aria-label="Direct link to Desktop Companion app" title="Direct link to Desktop Companion app" translate="no">​</a></h4>
<p>The Desktop Companion app provides the ability to record, transfer, process, validate and visualize Aria data through a desktop interface. Users can also request MPS data for single recordings. Please note, Aria Studio is the preferred GUI for working with Aria data.</p>
<p>While Aria data can be downloaded using the Desktop app, it may be faster to <a class="" href="/docs/aria_docs/ARK_quickstart#download-data">download the data using other means</a>.</p>
<p>The Desktop Companion app can be installed on:</p>
<ul>
<li class="">Mac Intel or Mac ARM-based (M1) with MacOS 11.3 (Big Sur) or newer</li>
<li class="">Windows 10 x86_64 with DirectX (or OpenGL but the latest drivers should be installed)</li>
<li class="">Windows 11 may work, but is not actively supported at this time</li>
<li class="">Linux, debian package for Ubuntu, 22.04 LTS version. The app was only tested for that specific version under Gnome 42.5 and X11 (X Server) as well as Wayland. Any other debian distribution (Ubuntu 22.04 fork such as Kubuntu, Mint etc.) or environment may or may not work.<!-- -->
<ul>
<li class="">V36 only, please use the <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/request_mps/mps_cli" target="_blank" rel="noopener noreferrer" class="">MPS CLI</a> or <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/aria_studio" target="_blank" rel="noopener noreferrer" class="">Aria Studio</a> to request Hand Tracking MPS</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="egoblur">EgoBlur<a href="#egoblur" class="hash-link" aria-label="Direct link to EgoBlur" title="Direct link to EgoBlur" translate="no">​</a></h3>
<p>EgoBlur is an open source AI model from Meta to preserve privacy by detecting and blurring PII from images. We provide two FasterRCNN-based detector models, for face blurring and license plates and perform consistently across the full range of ‘responsible AI labels’, as defined by the <a href="https://ai.meta.com/datasets/casual-conversations-v2-dataset/" target="_blank" rel="noopener noreferrer" class="">CCV2 dataset</a>.</p>
<ul>
<li class="">EgoBlur Research Paper - <a href="https://arxiv.org/abs/2308.13093" target="_blank" rel="noopener noreferrer" class="">EgoBlur: Responsible Innovation in Aria</a></li>
<li class=""><a href="https://www.projectaria.com/tools/egoblur/" target="_blank" rel="noopener noreferrer" class="">About EgoBlur</a>
<ul>
<li class=""><a href="https://www.projectaria.com/tools/egoblur/#accessEgoBlur" target="_blank" rel="noopener noreferrer" class="">Download the Models</a></li>
</ul>
</li>
<li class="">EgoBlur VRS Utilities - C++ tool for working with Aria VRS files<!-- -->
<ul>
<li class="">Go to the <a href="https://github.com/facebookresearch/EgoBlur/blob/main/tools/README.md" target="_blank" rel="noopener noreferrer" class="">EgoBlur VRS Utilities Readme</a> for detailed instructions</li>
</ul>
</li>
<li class="">EgoBlur Demo - Python3 tool for working with PNG, JPEG or MP4 files<!-- -->
<ul>
<li class="">Go to the <a href="https://github.com/facebookresearch/EgoBlur/blob/main/tools/README.md" target="_blank" rel="noopener noreferrer" class="">EgoBlur Readme</a> for detailed instructions</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="project-aria-eye-tracking">Project Aria Eye Tracking<a href="#project-aria-eye-tracking" class="hash-link" aria-label="Direct link to Project Aria Eye Tracking" title="Direct link to Project Aria Eye Tracking" translate="no">​</a></h3>
<p><a href="https://github.com/facebookresearch/projectaria_eyetracking" target="_blank" rel="noopener noreferrer" class="">Project Aria Eye Tracking</a> provides an open source inference code for the <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/mps_eye_gaze" target="_blank" rel="noopener noreferrer" class="">Pre March 2024 Eye Gaze Model</a> used by MPS.</p>
<ul>
<li class="">Provides the ability to generate eye gaze data using the old model, if that is more suited to your research use case or if you’re not able to request MPS</li>
<li class="">This code can be used on downloaded data or when streaming data using the Aria Client SDK</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-do-i-use-aria-data">How do I use Aria data?<a href="#how-do-i-use-aria-data" class="hash-link" aria-label="Direct link to How do I use Aria data?" title="Direct link to How do I use Aria data?" translate="no">​</a></h2>
<p>Because of Aria’s unique data structure, we recommend using Project Aria Tools as an interface to access the data via an abstraction (an X_provider string) that allows users to iterate through all the sensor recordings.</p>
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/aria_vrs" target="_blank" rel="noopener noreferrer" class="">How Project Aria Uses VRS</a></li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/getting_started" target="_blank" rel="noopener noreferrer" class="">Getting Started Guide</a> (view sample data via Jupyter Notebook or Google Colab)</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/installation/download_codebase" target="_blank" rel="noopener noreferrer" class="">Download Project Aria Tools Codebase</a></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-do-i-use-the-imu-data">How do I use the IMU data?<a href="#how-do-i-use-the-imu-data" class="hash-link" aria-label="Direct link to How do I use the IMU data?" title="Direct link to How do I use the IMU data?" translate="no">​</a></h3>
<div id="calibration"></div>
<p>We recommend using <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_trajectory" target="_blank" rel="noopener noreferrer" class="">Trajectory MPS outputs</a> instead of raw IMU data wherever possible. Go to <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/mps" target="_blank" rel="noopener noreferrer" class="">MPS Code Snippets</a> for how to load open loop or closed loop trajectory data.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-calibration-information-is-available">What calibration information is available?<a href="#what-calibration-information-is-available" class="hash-link" aria-label="Direct link to What calibration information is available?" title="Direct link to What calibration information is available?" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="general-calibration-concepts">General calibration concepts<a href="#general-calibration-concepts" class="hash-link" aria-label="Direct link to General calibration concepts" title="Direct link to General calibration concepts" translate="no">​</a></h4>
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/coordinate_convention/2d_image_coordinate_system_convention" target="_blank" rel="noopener noreferrer" class="">2D Image Coordinate System Conventions</a> (intrinsics)</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/coordinate_convention/3d_coordinate_frame_convention" target="_blank" rel="noopener noreferrer" class="">3D Coordinate Frame Conventions</a> (extrinsics, non-visual sensor coordinate systems and CPF)</li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/core_code_snippets/calibration" target="_blank" rel="noopener noreferrer" class="">Calibration Code Snippets</a></li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights" target="_blank" rel="noopener noreferrer" class="">Tech Insights</a> - technical deeper dives on domain-specific topics, such as how we model sensors mathematically in calibration:<!-- -->
<ul>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights/camera_intrinsic_models" target="_blank" rel="noopener noreferrer" class="">Camera intrinsic models</a></li>
<li class=""><a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights/sensor_measurement_model" target="_blank" rel="noopener noreferrer" class="">Sensor measurement model</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="slam-mps-calibration-data">SLAM MPS Calibration data<a href="#slam-mps-calibration-data" class="hash-link" aria-label="Direct link to SLAM MPS Calibration data" title="Direct link to SLAM MPS Calibration data" translate="no">​</a></h4>
<p><code>Online_calibration.jsonl</code> is a SLAM MPS output that contains one json online calibration record per line. Each record is a json dict object that contains timestamp metadata and the result of online calibration for the cameras and IMUs.</p>
<p>The calibration parameters contain <a href="https://facebookresearch.github.io/projectaria_tools/docs/tech_insights/camera_intrinsic_models" target="_blank" rel="noopener noreferrer" class="">intrinsics</a> and <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/coordinate_convention/3d_coordinate_frame_convention" target="_blank" rel="noopener noreferrer" class="">extrinsics</a> parameters for each sensor as well as a time offsets that best temporally align their data.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="in-session-eye-gaze-calibration">In-Session Eye Gaze Calibration<a href="#in-session-eye-gaze-calibration" class="hash-link" aria-label="Direct link to In-Session Eye Gaze Calibration" title="Direct link to In-Session Eye Gaze Calibration" translate="no">​</a></h4>
<p>This is not related to standard calibration. <a href="https://facebookresearch.github.io/projectaria_tools/docs/ARK/mps/eye_gaze_calibration" target="_blank" rel="noopener noreferrer" class="">In-Session Eye Gaze Calibration</a> enables researchers to improve the eye gaze estimations in Eye Gaze MPS outputs, enabling researchers to more accurately determine where wearers are looking during the recordings.</p>
<p>When users collect data using Aria glasses, they can initiate In-Session Eye Gaze Calibration. Once they’ve performed this task personalized, as well as general Eye Gaze MPS, can be generated. Every person is unique in terms of how they move their eyes and look at objects, so the personalized_eye_gaze estimation is expected to be more accurate for the individual.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="should-i-use-vrs-or-project-aria-tools">Should I use VRS or Project Aria Tools?<a href="#should-i-use-vrs-or-project-aria-tools" class="hash-link" aria-label="Direct link to Should I use VRS or Project Aria Tools?" title="Direct link to Should I use VRS or Project Aria Tools?" translate="no">​</a></h3>
<p>Project Aria Tools provides VrsDataProvider which offers some, but not all, of the VRS API capabilities. Go to <a href="https://facebookresearch.github.io/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs" target="_blank" rel="noopener noreferrer" class="">How Project Aria Uses VRS</a> for more information.</p>
<p>We’ve tailored VrsDataProvider to meet the requirements of people using Aria data. If there are capabilities in the VRS API that you would like to access when using Project Aria Tools, please use one of our <a href="https://facebookresearch.github.io/projectaria_tools/docs/support" target="_blank" rel="noopener noreferrer" class="">Support channels</a> to let us know what you’re looking for and what features you would like.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-do-i-get-involved">How do I get involved?<a href="#how-do-i-get-involved" class="hash-link" aria-label="Direct link to How do I get involved?" title="Direct link to How do I get involved?" translate="no">​</a></h2>
<p>The Project Aria <a href="https://www.projectaria.com/contact/" target="_blank" rel="noopener noreferrer" class="">Contact Us</a> page contains a variety of ways to get in touch. We’d love to hear from you.</p>
<p>Download and explore our various <a href="https://www.projectaria.com/datasets/" target="_blank" rel="noopener noreferrer" class="">open datasets</a> and let us know how it goes!</p>
<p>For questions or feature requests relating to Project Aria Tools, we encourage you to post to the <a href="https://github.com/facebookresearch/projectaria_tools/issues" target="_blank" rel="noopener noreferrer" class="">Issues page on GitHub</a>.</p>
<p>Go to our <a href="https://facebookresearch.github.io/projectaria_tools/docs/attribution_citation" target="_blank" rel="noopener noreferrer" class="">Attribution and Contributing page</a> if you’d like to find out how to cite Project Aria or contribute to our open tooling.</p>
<p><a href="https://www.projectaria.com/challenges/" target="_blank" rel="noopener noreferrer" class="">Research Challenges</a> are posted to Projectaria.com. Open research challenges allow us to collectively accelerate the state-of-the-art with the community. We believe these challenges will help to establish a baseline for external researchers to build and foster reproducible research on egocentric Computer Vision and AI/ML algorithms for scene perception, reconstruction and understanding, and contextual AI.</p>
<p>If you’d like to collect your own data, or use Project Aria glasses in streaming applications go to <a href="https://www.projectaria.com/research-kit/" target="_blank" rel="noopener noreferrer" class="">Aria Research Kit intro page</a> at <a href="https://www.projectaria.com/" target="_blank" rel="noopener noreferrer" class="">projectaria.com</a> to find out how to become a research partner.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/aria_docs/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction to Project Aria Docs</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/aria_docs/ARK_quickstart"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Getting Started With Aria Glasses</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-project-aria" class="table-of-contents__link toc-highlight">What is Project Aria?</a></li><li><a href="#what-project-aria-data-is-available" class="table-of-contents__link toc-highlight">What Project Aria data is available?</a></li><li><a href="#what-can-project-aria-be-used-for" class="table-of-contents__link toc-highlight">What can Project Aria be used for?</a></li><li><a href="#what-is-the-software-ecosystem" class="table-of-contents__link toc-highlight">What is the software ecosystem?</a><ul><li><a href="#project-aria-tools" class="table-of-contents__link toc-highlight">Project Aria Tools</a></li><li><a href="#aria-research-kit" class="table-of-contents__link toc-highlight">Aria Research Kit</a></li><li><a href="#egoblur" class="table-of-contents__link toc-highlight">EgoBlur</a></li><li><a href="#project-aria-eye-tracking" class="table-of-contents__link toc-highlight">Project Aria Eye Tracking</a></li></ul></li><li><a href="#how-do-i-use-aria-data" class="table-of-contents__link toc-highlight">How do I use Aria data?</a><ul><li><a href="#how-do-i-use-the-imu-data" class="table-of-contents__link toc-highlight">How do I use the IMU data?</a></li><li><a href="#what-calibration-information-is-available" class="table-of-contents__link toc-highlight">What calibration information is available?</a></li><li><a href="#should-i-use-vrs-or-project-aria-tools" class="table-of-contents__link toc-highlight">Should I use VRS or Project Aria Tools?</a></li></ul></li><li><a href="#how-do-i-get-involved" class="table-of-contents__link toc-highlight">How do I get involved?</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">External Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebookresearch/hot3d/commit/a23c9dc4aa1e0679a5089af376e7cbd32434c2f5" target="_blank" rel="noopener noreferrer" class="footer__link-item">HOT3D README Commit<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.graphicmedicine.org/comic-reviews/past-tense-facing-family-secrets-and-finding-myself-in-therapy/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Book Review: Past Tense<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://ngombor.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Ngombor Community Development Alliance<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Featured Content</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/aria_docs/faq">Project Aria FAQ</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/aria_docs/mps/mps_cli_guide">MPS Guide - Cloud Services</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/acrolinx">Acrolinx - an AI Content Governance Tool</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://mailchi.mp/520551e04a4d/documentarians-rock" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://lizargall.github.io/blog/rss.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item">RSS feed<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/lizargall/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/lizargall" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Project Aria content was released under the Apache 2.0 license, the rest is © Liz Argall | If you'd like to license or reuse my content, lets chat! liz@lizargall.com|  Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>