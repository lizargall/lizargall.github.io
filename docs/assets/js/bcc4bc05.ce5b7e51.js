"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[7259],{1180(e,s,r){r.d(s,{A:()=>n});const n=r.p+"assets/images/aria_ref_frames_all_black-3c9d0c2f0c7717d0e9a9d9912aa93ce7.png"},5761(e,s,r){r.r(s),r.d(s,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>a,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"adt/sensors-measurements","title":"Sensors and Measurements","description":"This page provides an overview of the sensors and measurements we use for Project Aria devices","source":"@site/docs/adt/sensors-measurements.mdx","sourceDirName":"adt","slug":"/adt/sensors-measurements","permalink":"/docs/adt/sensors-measurements","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":30,"frontMatter":{"sidebar_position":30,"id":"sensors-measurements","title":"Sensors and Measurements","description":"This page provides an overview of the sensors and measurements we use for Project Aria devices"},"sidebar":"tutorialSidebar","previous":{"title":"Accessing Sensor Data","permalink":"/docs/adt/dataprovider"},"next":{"title":"Aria Pilot Dataset Overview","permalink":"/docs/adt/pilotdata-index"}}');var i=r(4848),t=r(8453);const a={sidebar_position:30,id:"sensors-measurements",title:"Sensors and Measurements",description:"This page provides an overview of the sensors and measurements we use for Project Aria devices"},d="Sensors and Measurements",o={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Sensors",id:"sensors",level:2},{value:"Naming conventions for all tools",id:"naming-conventions-for-all-tools",level:2},{value:"RecordableTypeId",id:"recordabletypeid",level:3},{value:"VRS instance ID",id:"vrs-instance-id",level:3},{value:"StreamId",id:"streamid",level:3},{value:"Coordinate Systems",id:"coordinate-systems",level:2},{value:"Time",id:"time",level:2},{value:"GPS",id:"gps",level:2},{value:"Units of Measurement",id:"units-of-measurement",level:2}];function l(e){const s={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"sensors-and-measurements",children:"Sensors and Measurements"})}),"\n",(0,i.jsx)(s.admonition,{title:"Writing Sample",type:"info",children:(0,i.jsxs)(s.p,{children:["This page is an archive of technical writing I did for Project Aria. For the most up to date documentation go to ",(0,i.jsx)(s.a,{href:"https://facebookresearch.github.io/projectaria_tools/docs/intro",children:"Project Aria Docs"}),"."]})}),"\n",(0,i.jsx)(s.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(s.p,{children:"This page provides an overview of the sensors and measurements we use for Project Aria, covering:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"#sensors",children:"Project Aria device sensors"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"#naming",children:"Naming conventions for all the tools and IDs used for sensors"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"#coordinate",children:"Coordinate systems"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"#time",children:"Time (inc time stamping and camera shutter types)"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"#gps",children:"GPS"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.a,{href:"#units",children:"Units of measurement"})}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"sensors",children:"Sensors"}),"\n",(0,i.jsxs)(s.p,{children:["Project Aria sensor data is stored in ",(0,i.jsx)(s.a,{href:"https://facebookresearch.github.io/vrs/docs/Overview",children:"VRS"})," and can record with:"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"1 x 110 degree HFOV Rolling Shutter High Resolution RGB camera, up to 8MP"}),"\n",(0,i.jsx)(s.li,{children:"2 x 150 HFOV / 120 degree VFOV Global Shutter mono cameras for SLAM & hand tracking, 640 x 480 pix"}),"\n",(0,i.jsx)(s.li,{children:"2 x 80 degree DFOV Eye-tracking Global Shutter mono cameras with IR illumination, 320 x 240 pix"}),"\n",(0,i.jsx)(s.li,{children:"2 x IMU, Barometer and Magnetometer (one IMU is 1KHz and the other is 800Hz)"}),"\n",(0,i.jsx)(s.li,{children:"7 x 48 KHz spatial microphones"}),"\n",(0,i.jsx)(s.li,{children:"GPS, Bluetooth and WiFi"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Researchers can use different sensor profiles when collecting data. Sensor profiles allow them to choose which sensors record as well as what settings to use. Settings options include what camera resolution to use and whether the output is RAW (no encoding) or JPEG (compressed)."}),"\n",(0,i.jsx)("div",{id:"naming"}),"\n",(0,i.jsx)(s.admonition,{type:"tip",children:(0,i.jsx)(s.p,{children:"Cameras on Project Aria devices are installed sideways. By default, images are reported and viewed as they were provided by cameras and will appear sideways."})}),"\n",(0,i.jsx)(s.h2,{id:"naming-conventions-for-all-tools",children:"Naming conventions for all tools"}),"\n",(0,i.jsx)(s.p,{children:"We use the sensor name set as the main query type for each sensor in all tools. The naming conventions for all sensors are:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Cameras: camera-slam-left, camera-slam-right, camera-et-left, camera-et-right, camera-rgb"}),"\n",(0,i.jsx)(s.li,{children:"IMUs: imu-left, imu-right"}),"\n",(0,i.jsx)(s.li,{children:"Magnetometers: mag0"}),"\n",(0,i.jsx)(s.li,{children:"Microphones: mic0, mic1, ..., mic6"}),"\n",(0,i.jsx)(s.li,{children:"Barometer: baro0"}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:['Each sensor is associated with an instance-invariant name. For example, the left SLAM camera is named as "camera-slam-left". The name set of supported sensors can be fetched in Python3 with the ',(0,i.jsx)(s.code,{children:"deviceModel.getCameraLabels()"})," command:"]}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{children:">>> deviceModel.getCameraLabels()\n['camera-et-left', 'camera-et-right', 'camera-rgb', 'camera-slam-left', 'camera-slam-right']\n>>> deviceModel.getImuLabels()\n['imu-left', 'imu-right']`\n"})}),"\n",(0,i.jsx)(s.admonition,{type:"note",children:(0,i.jsx)(s.p,{children:"Left/Right are relative to the left and right side of the glasses when the user is wearing the device. Another way to differentiate between the two sides is that the left SLAM camera is closer to the RGB camera."})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Table 1:"})," ",(0,i.jsx)(s.em,{children:"IDs Used for Sensors"})]}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"StreamId"}),(0,i.jsx)(s.th,{children:"Stream"}),(0,i.jsx)(s.th,{children:"vrs::RecordableTypeId"}),(0,i.jsx)(s.th,{children:"VRS Instance ID"}),(0,i.jsx)(s.th,{children:"Calibration labels for coordinate transform"}),(0,i.jsx)(s.th,{children:"DataProvider API"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"211-1"}),(0,i.jsx)(s.td,{children:"Eye tracking camera"}),(0,i.jsx)(s.td,{children:"EyeCameraRecordableClass (211)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsxs)(s.td,{children:[(0,i.jsx)(s.code,{children:"camera-et-left"})," ",(0,i.jsx)(s.code,{children:"camera-et-right"})]}),(0,i.jsx)(s.td,{children:"getEyeCameraPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"214-1"}),(0,i.jsx)(s.td,{children:"RGB camera"}),(0,i.jsx)(s.td,{children:"RgbCameraRecordableClass (214)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"camera-rgb"})}),(0,i.jsx)(s.td,{children:"getRgbCameraPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"231-1"}),(0,i.jsx)(s.td,{children:"Microphones"}),(0,i.jsx)(s.td,{children:"StereoAudioRecordableClass (231)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsxs)(s.td,{children:[(0,i.jsx)(s.code,{children:"mic0"}),", ",(0,i.jsx)(s.code,{children:"mic1"}),", ",(0,i.jsx)(s.code,{children:"mic2"}),", ..., ",(0,i.jsx)(s.code,{children:"mic6"})]}),(0,i.jsx)(s.td,{children:"getAudioPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"247-1"}),(0,i.jsx)(s.td,{children:"Barometer"}),(0,i.jsx)(s.td,{children:"BarometerRecordableClass (247)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"baro0"})}),(0,i.jsx)(s.td,{children:"getBarometerPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"281-1"}),(0,i.jsx)(s.td,{children:"GPS"}),(0,i.jsx)(s.td,{children:"GpsRecordableClass (281)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{}),(0,i.jsx)(s.td,{children:"getGpsPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"283-1"}),(0,i.jsx)(s.td,{children:"Bluetooth beacon"}),(0,i.jsx)(s.td,{children:"BluetoothBeaconRecordableClass (283)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{}),(0,i.jsx)(s.td,{children:"getBluetoothBeaconPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"285-1"}),(0,i.jsx)(s.td,{children:"Time domain"}),(0,i.jsx)(s.td,{children:"TimeRecordableClass (285)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{}),(0,i.jsx)(s.td,{children:"getTimeSyncPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"1201-1"}),(0,i.jsx)(s.td,{children:"SLAM Camera Left"}),(0,i.jsx)(s.td,{children:"SlamCameraData (1201)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"camera-slam-left"})}),(0,i.jsx)(s.td,{children:"getSlamLeftCameraPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"1201-2"}),(0,i.jsx)(s.td,{children:"SLAM Camera Right"}),(0,i.jsx)(s.td,{children:"SlamCameraData (1201)"}),(0,i.jsx)(s.td,{children:"2"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"camera-slam-right"})}),(0,i.jsx)(s.td,{children:"getSlamRightCameraPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"1202-1"}),(0,i.jsx)(s.td,{children:"IMU sensor 1 (1KHz)"}),(0,i.jsx)(s.td,{children:"SlamImuData (1202)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"imu-right"})}),(0,i.jsx)(s.td,{children:"getImuRightPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"1202-2"}),(0,i.jsx)(s.td,{children:"IMU sensor 2 (800Hz)"}),(0,i.jsx)(s.td,{children:"SlamImuData (1202)"}),(0,i.jsx)(s.td,{children:"2"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"imu-left"})}),(0,i.jsx)(s.td,{children:"getImuLeftPlayer()"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"1203-1"}),(0,i.jsx)(s.td,{children:"Magnetometer"}),(0,i.jsx)(s.td,{children:"SlamMagnetometerData (1203)"}),(0,i.jsx)(s.td,{children:"1"}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.code,{children:"mag0"})}),(0,i.jsx)(s.td,{children:"getMagnetometerPlayer()"})]})]})]}),"\n",(0,i.jsx)(s.h3,{id:"recordabletypeid",children:"RecordableTypeId"}),"\n",(0,i.jsxs)(s.p,{children:["VRS files contain multiple streams, each associated with a device type, defined by a ",(0,i.jsx)(s.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/StreamId.h",children:(0,i.jsx)(s.code,{children:"RecordableTypeId"})})," enum value. For Project Aria, each kind of sensor is defined as a device type. See ",(0,i.jsx)(s.a,{href:"https://facebookresearch.github.io/vrs/docs/FileStructure#streams",children:"Streams"})," in VRS's Documentation for more information."]}),"\n",(0,i.jsx)(s.h3,{id:"vrs-instance-id",children:"VRS instance ID"}),"\n",(0,i.jsx)(s.p,{children:"A unique ID number for each instance of a sensor type. The first instance of a sensor type has the number 1, the second sensor number 2, and so on."}),"\n",(0,i.jsx)(s.h3,{id:"streamid",children:"StreamId"}),"\n",(0,i.jsx)(s.p,{children:"Unique identifier for a stream of data in VRS."}),"\n",(0,i.jsx)("div",{id:"coordinate"}),"\n",(0,i.jsx)(s.p,{children:'A StreamId identifies each instance of a sensor, device, algorithm, or "something" that produces a stream of records. A StreamId combines a RecordableTypeId that describes the type of sensor device, or other producer of records, and an instance id, to differentiate streams coming from different sensors of the same type.'}),"\n",(0,i.jsx)(s.h2,{id:"coordinate-systems",children:"Coordinate Systems"}),"\n",(0,i.jsx)(s.p,{children:"Applications like stereo vision and navigation usually handle 2D and 3D points in different spaces, and transformations need to be conducted between them. With Project Aria data, we attach a local R3 coordinate frame to each sensor."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{alt:"image of aria device with all the sensors",src:r(1180).A+"",width:"3339",height:"1094"})}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Figure 1:"})," ",(0,i.jsx)(s.em,{children:"Sensors and Sensor Directions on Project Aria Devices"})]}),"\n",(0,i.jsx)(s.p,{children:"Go to [Calibration Sensor Data] for more information and code snippets."}),"\n",(0,i.jsx)(s.h2,{id:"time",children:"Time"}),"\n",(0,i.jsx)(s.p,{children:"Every signal (or Record in VRS terms) collected by sensors is stamped with a timestamp from a common clock. For Project Aria data, this is usually the local time clock. All records are sorted in monotonically increasing order in a VRS file. We use the following sensor-specific conventions on timestamps:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"For all cameras, the timestamp of a frame is the center of exposure time, a.k.a. the middle point of exposure interval."}),"\n",(0,i.jsx)(s.li,{children:"The RGB camera is a rolling shutter, with a readout time of 5ms (when recording at 1408x1408) or 15ms (when recording at 2880x2880) from first to last line. The recorded timestamp of an RGB frame is the center of exposure timestamp of the middle row of the image. SLAM and eye tracking cameras are global shutter and all of the pixels in the image are exposed simultaneously."}),"\n",(0,i.jsxs)(s.li,{children:["IMUs, accelerometers and gyroscopes may have a time offset from the local time clock. This is due to internal signal processing in the IMU, which introduces a small time delay. These are estimated during calibration and stored in the JSON as ",(0,i.jsx)(s.code,{children:"TimeOffsetSec_Device_Gyro"})," and ",(0,i.jsx)(s.code,{children:"TimeOffsetSec_Device_Accel"})," respectively."]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"gps",children:"GPS"}),"\n",(0,i.jsx)("div",{id:"units"}),"\n",(0,i.jsxs)(s.p,{children:["Horizontal and vertical accuracy are calculated using ",(0,i.jsx)(s.a,{href:"https://developer.android.com/reference/android/location/Location#getAccuracy",children:"Android definitions"}),"."]}),"\n",(0,i.jsx)(s.h2,{id:"units-of-measurement",children:"Units of Measurement"}),"\n",(0,i.jsx)(s.p,{children:"The units for numerical values in the code and documentation are:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Coordinates, location and distance in world space: meters (m)"}),"\n",(0,i.jsx)(s.li,{children:"Coordinates in image space: pixels"}),"\n",(0,i.jsx)(s.li,{children:"Timestamp and time intervals: seconds (s)"}),"\n",(0,i.jsx)(s.li,{children:"Angles: radians (rad)"}),"\n",(0,i.jsx)(s.li,{children:"Acceleration: m/s^2"}),"\n",(0,i.jsx)(s.li,{children:"Angular velocity: rad/s"}),"\n",(0,i.jsx)(s.li,{children:"Pressure: pascal (Pa)"}),"\n",(0,i.jsx)(s.li,{children:"Temperature: celsius (\xb0C)"}),"\n",(0,i.jsx)(s.li,{children:"Magnetometer: Tesla (T)"}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453(e,s,r){r.d(s,{R:()=>a,x:()=>d});var n=r(6540);const i={},t=n.createContext(i);function a(e){const s=n.useContext(t);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function d(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),n.createElement(t.Provider,{value:s},e.children)}}}]);